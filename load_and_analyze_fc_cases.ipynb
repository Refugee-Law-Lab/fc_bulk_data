{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to load and analyze Federal Court cases\n",
    "\n",
    "Sean Rehaag\n",
    "\n",
    "License: Creative Commons Attribution-NonCommercial 4.0 International [(CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/). NOTE: Users must also comply with upstream [licensing](https://www.fct-cf.gc.ca/en/pages/important-notices) for the FC data source, as well as requests on source urls not to allow indexing of the documents by search engines to protect privacy. As a result, users must not make the data available in formats or locations that can be indexed by search engines.\n",
    "\n",
    "Dataset & Code to be cited as: \n",
    "\n",
    "    Sean Rehaag, \"Federal Court Bulk Decisions Dataset\" (2023), online: Refugee Law Laboratory <https://refugeelab.ca/bulk-data/fc/>.\n",
    "\n",
    "Notes:\n",
    "\n",
    "(1) Data Source: [Federal Court](https://www.fct-cf.gc.ca). \n",
    "\n",
    "(2) Unofficial Data: The data are unofficial reproductions of materials on the Federal Court website. Links to official versions are included in the dataset.\n",
    "\n",
    "(3) Non-Affiliation / Endorsement: The data has been collected and reproduced without any affiliation or endorsement from the Federal Court.\n",
    "\n",
    "(4) Non-Commerical Use: As indicated in the license, data may be used for non-commercial use (with attribution) only. For commercial use, see the Federal Court of Appeal website's [Terms of Use](https://www.fct-cf.gc.ca/en/pages/important-notices).\n",
    "\n",
    "(5) Accuracy: Data was collected and processed programmatically for the purposes of academic research. While we make best efforts to ensure accuracy, data gathering of this kind inevitably involves errors. As such the data should be viewed as preliminary information aimed to prompt further research and discussion, rather than as definitive information. \n",
    "\n",
    "(6) Limitation: Only includes cases with neutral citation, which began to be used in 2001\n",
    "\n",
    "(7) Delay: Decisions may take many months to be translated (sometimes over a year). As a result, in the most recent years, decisions may only be available in one language.\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "    pip install pandas\n",
    "\n",
    "### If using parquet\n",
    "\n",
    "    pip install pyarrow\n",
    "\n",
    "### if loading remotely (other than via Hugging Face)\n",
    "    \n",
    "    pip install requests\n",
    "\n",
    "### If loading remotely via Hugging Face\n",
    "\n",
    "    pip install datasets\n",
    "    \n",
    "\n",
    "(Written on Python 3.9.12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Four Options: Local & Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Load Hugging Face dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"refugee-law-lab/canadian-legal-data\", \"RLLR\", split=\"train\")\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Load parquet data remotely from Huggingface without cloning repo\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = 'https://huggingface.co/datasets/refugee-law-lab/canadian-legal-data/resolve/main/FC/train.parquet'\n",
    "\n",
    "# load data\n",
    "results = requests.get(url)\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.read_parquet(BytesIO(results.content))\n",
    "\n",
    "df.head()\n",
    "\n",
    "# (if code fails, add engine='pyarrow' to read_parquet() function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 3: Load data remotely from GitHub without cloning repo\n",
    "# Note: load time varies depending on internet connection (approx 1.5 GB of data for all years/languages)\n",
    "# This is the slowest loading option.\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Set variables\n",
    "start_year = 2001  # First year of data sought (1877 +)\n",
    "end_year = 2024  # Last year of data sought (2024 -)\n",
    "languages_sought = ['en', 'fr']  # languages in list e.g. ['en', 'fr'] or ['en']\n",
    "\n",
    "\n",
    "base_ulr = 'https://raw.githubusercontent.com/Refugee-Law-Lab/fc_bulk_data/master/DATA/YEARLY/'\n",
    "\n",
    "# load data\n",
    "results = []\n",
    "for year in range(start_year, end_year+1):\n",
    "    for language in languages_sought:\n",
    "        url = base_ulr + f'{year}_{language}.json'\n",
    "        results.extend(requests.get(url).json())\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 4: Load data locally via cloned repo\n",
    "\n",
    "# First, clone git repo\n",
    "# Then run this code to load data\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "# Set variables\n",
    "start_year = 2001  # First year of data sought (1877 +)\n",
    "end_year = 2024  # Last year of data sought (2024 -)\n",
    "languages_sought = ['en', 'fr']  # languages in list e.g. ['en', 'fr'] or ['en']\n",
    "\n",
    "# Set path to data\n",
    "data_path = pathlib.Path('DATA/YEARLY/')\n",
    "\n",
    "# load data\n",
    "results = []\n",
    "for year in range(start_year, end_year+1):\n",
    "    for language in languages_sought:\n",
    "        with open(data_path / f'{year}_{language}.json') as f:\n",
    "            results.extend(json.load(f))\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language counts\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly counts\n",
    "year_counts = df.year.value_counts()\n",
    "years_count = sorted(year_counts.index)\n",
    "for year_count in years_count:\n",
    "    print(f'{year_count}: {year_counts[year_count]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
